{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Data-structures :- stacks,queues,binary search trees and graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Stack:\n",
    "     def __init__(self):\n",
    "         self.items = []\n",
    "\n",
    "     def isEmpty(self):\n",
    "         return self.items == []\n",
    "\n",
    "     def push(self, item):\n",
    "         self.items.append(item)\n",
    "\n",
    "     def pop(self):\n",
    "         return self.items.pop()\n",
    "\n",
    "     def peek(self):\n",
    "         return self.items[len(self.items)-1]\n",
    "\n",
    "     def size(self):\n",
    "         return len(self.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word\n"
     ]
    }
   ],
   "source": [
    "S = Stack()\n",
    "S.push('word')\n",
    "print(S.peek())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Queue:\n",
    "    def __init__(self):\n",
    "        self.items = []\n",
    "\n",
    "    def isEmpty(self):\n",
    "        return self.items == []\n",
    "\n",
    "    def enqueue(self, item):\n",
    "        self.items.insert(0,item)\n",
    "\n",
    "    def dequeue(self):\n",
    "        return self.items.pop()\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TreeNode:\n",
    "    def __init__(self,key,val,left=None,right=None,parent=None):\n",
    "        self.key = key\n",
    "        self.payload = val\n",
    "        self.leftChild = left\n",
    "        self.rightChild = right\n",
    "        self.parent = parent\n",
    "\n",
    "    def hasLeftChild(self):\n",
    "        return self.leftChild\n",
    "\n",
    "    def hasRightChild(self):\n",
    "        return self.rightChild\n",
    "\n",
    "    def isLeftChild(self):\n",
    "        return self.parent and self.parent.leftChild == self\n",
    "\n",
    "    def isRightChild(self):\n",
    "        return self.parent and self.parent.rightChild == self\n",
    "\n",
    "    def isRoot(self):\n",
    "        return not self.parent\n",
    "\n",
    "    def isLeaf(self):\n",
    "        return not (self.rightChild or self.leftChild)\n",
    "\n",
    "    def hasAnyChildren(self):\n",
    "        return self.rightChild or self.leftChild\n",
    "\n",
    "    def hasBothChildren(self):\n",
    "        return self.rightChild and self.leftChild\n",
    "\n",
    "    def replaceNodeData(self,key,value,lc,rc):\n",
    "        self.key = key\n",
    "        self.payload = value\n",
    "        self.leftChild = lc\n",
    "        self.rightChild = rc\n",
    "        if self.hasLeftChild():\n",
    "            self.leftChild.parent = self\n",
    "        if self.hasRightChild():\n",
    "            self.rightChild.parent = self\n",
    "\n",
    "\n",
    "class BinarySearchTree:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.root = None\n",
    "        self.size = 0\n",
    "\n",
    "    def length(self):\n",
    "        return self.size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def put(self,key,val):\n",
    "        if self.root:\n",
    "            self._put(key,val,self.root)\n",
    "        else:\n",
    "            self.root = TreeNode(key,val)\n",
    "        self.size = self.size + 1\n",
    "\n",
    "    def _put(self,key,val,currentNode):\n",
    "        if key < currentNode.key:\n",
    "            if currentNode.hasLeftChild():\n",
    "                   self._put(key,val,currentNode.leftChild)\n",
    "            else:\n",
    "                   currentNode.leftChild = TreeNode(key,val,parent=currentNode)\n",
    "        else:\n",
    "            if currentNode.hasRightChild():\n",
    "                   self._put(key,val,currentNode.rightChild)\n",
    "            else:\n",
    "                   currentNode.rightChild = TreeNode(key,val,parent=currentNode)\n",
    "\n",
    "    def __setitem__(self,k,v):\n",
    "       self.put(k,v)\n",
    "\n",
    "    def get(self,key):\n",
    "       if self.root:\n",
    "           res = self._get(key,self.root)\n",
    "           if res:\n",
    "                  return res.payload\n",
    "           else:\n",
    "                  return None\n",
    "       else:\n",
    "           return None\n",
    "\n",
    "    def _get(self,key,currentNode):\n",
    "       if not currentNode:\n",
    "           return None\n",
    "       elif currentNode.key == key:\n",
    "           return currentNode\n",
    "       elif key < currentNode.key:\n",
    "           return self._get(key,currentNode.leftChild)\n",
    "       else:\n",
    "           return self._get(key,currentNode.rightChild)\n",
    "\n",
    "    def __getitem__(self,key):\n",
    "       return self.get(key)\n",
    "\n",
    "    def __contains__(self,key):\n",
    "       if self._get(key,self.root):\n",
    "           return True\n",
    "       else:\n",
    "           return False\n",
    "\n",
    "    def delete(self,key):\n",
    "      if self.size > 1:\n",
    "         nodeToRemove = self._get(key,self.root)\n",
    "         if nodeToRemove:\n",
    "             self.remove(nodeToRemove)\n",
    "             self.size = self.size-1\n",
    "         else:\n",
    "             raise KeyError('Error, key not in tree')\n",
    "      elif self.size == 1 and self.root.key == key:\n",
    "         self.root = None\n",
    "         self.size = self.size - 1\n",
    "      else:\n",
    "         raise KeyError('Error, key not in tree')\n",
    "\n",
    "    def __delitem__(self,key):\n",
    "       self.delete(key)\n",
    "\n",
    "    def spliceOut(self):\n",
    "       if self.isLeaf():\n",
    "           if self.isLeftChild():\n",
    "                  self.parent.leftChild = None\n",
    "           else:\n",
    "                  self.parent.rightChild = None\n",
    "       elif self.hasAnyChildren():\n",
    "           if self.hasLeftChild():\n",
    "                  if self.isLeftChild():\n",
    "                     self.parent.leftChild = self.leftChild\n",
    "                  else:\n",
    "                     self.parent.rightChild = self.leftChild\n",
    "                  self.leftChild.parent = self.parent\n",
    "           else:\n",
    "                  if self.isLeftChild():\n",
    "                     self.parent.leftChild = self.rightChild\n",
    "                  else:\n",
    "                     self.parent.rightChild = self.rightChild\n",
    "                  self.rightChild.parent = self.parent\n",
    "\n",
    "    def findSuccessor(self):\n",
    "      succ = None\n",
    "      if self.hasRightChild():\n",
    "          succ = self.rightChild.findMin()\n",
    "      else:\n",
    "          if self.parent:\n",
    "                 if self.isLeftChild():\n",
    "                     succ = self.parent\n",
    "                 else:\n",
    "                     self.parent.rightChild = None\n",
    "                     succ = self.parent.findSuccessor()\n",
    "                     self.parent.rightChild = self\n",
    "      return succ\n",
    "\n",
    "    def findMin(self):\n",
    "      current = self\n",
    "      while current.hasLeftChild():\n",
    "          current = current.leftChild\n",
    "      return current\n",
    "\n",
    "    def remove(self,currentNode):\n",
    "         if currentNode.isLeaf(): #leaf\n",
    "           if currentNode == currentNode.parent.leftChild:\n",
    "               currentNode.parent.leftChild = None\n",
    "           else:\n",
    "               currentNode.parent.rightChild = None\n",
    "         elif currentNode.hasBothChildren(): #interior\n",
    "           succ = currentNode.findSuccessor()\n",
    "           succ.spliceOut()\n",
    "           currentNode.key = succ.key\n",
    "           currentNode.payload = succ.payload\n",
    "\n",
    "         else: # this node has one child\n",
    "           if currentNode.hasLeftChild():\n",
    "             if currentNode.isLeftChild():\n",
    "                 currentNode.leftChild.parent = currentNode.parent\n",
    "                 currentNode.parent.leftChild = currentNode.leftChild\n",
    "             elif currentNode.isRightChild():\n",
    "                 currentNode.leftChild.parent = currentNode.parent\n",
    "                 currentNode.parent.rightChild = currentNode.leftChild\n",
    "             else:\n",
    "                 currentNode.replaceNodeData(currentNode.leftChild.key,\n",
    "                                    currentNode.leftChild.payload,\n",
    "                                    currentNode.leftChild.leftChild,\n",
    "                                    currentNode.leftChild.rightChild)\n",
    "           else:\n",
    "             if currentNode.isLeftChild():\n",
    "                 currentNode.rightChild.parent = currentNode.parent\n",
    "                 currentNode.parent.leftChild = currentNode.rightChild\n",
    "             elif currentNode.isRightChild():\n",
    "                 currentNode.rightChild.parent = currentNode.parent\n",
    "                 currentNode.parent.rightChild = currentNode.rightChild\n",
    "             else:\n",
    "                 currentNode.replaceNodeData(currentNode.rightChild.key,\n",
    "                                    currentNode.rightChild.payload,\n",
    "                                    currentNode.rightChild.leftChild,\n",
    "                                    currentNode.rightChild.rightChild)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Vertex:\n",
    "    def __init__(self,key):\n",
    "        self.id = key\n",
    "        self.connectedTo = {}\n",
    "\n",
    "    def addNeighbor(self,nbr,weight=0):\n",
    "        self.connectedTo[nbr] = weight\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.id) + ' connectedTo: ' + str([x.id for x in self.connectedTo])\n",
    "\n",
    "    def getConnections(self):\n",
    "        return self.connectedTo.keys()\n",
    "\n",
    "    def getId(self):\n",
    "        return self.id\n",
    "\n",
    "    def getWeight(self,nbr):\n",
    "        return self.connectedTo[nbr]\n",
    "    \n",
    "class Graph:\n",
    "    def __init__(self):\n",
    "        self.vertList = {}\n",
    "        self.numVertices = 0\n",
    "\n",
    "    def addVertex(self,key):\n",
    "        self.numVertices = self.numVertices + 1\n",
    "        newVertex = Vertex(key)\n",
    "        self.vertList[key] = newVertex\n",
    "        return newVertex\n",
    "\n",
    "    def getVertex(self,n):\n",
    "        if n in self.vertList:\n",
    "            return self.vertList[n]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def __contains__(self,n):\n",
    "        return n in self.vertList\n",
    "\n",
    "    def addEdge(self,f,t,cost=0):\n",
    "        if f not in self.vertList:\n",
    "            nv = self.addVertex(f)\n",
    "        if t not in self.vertList:\n",
    "            nv = self.addVertex(t)\n",
    "        self.vertList[f].addNeighbor(self.vertList[t], cost)\n",
    "\n",
    "    def getVertices(self):\n",
    "        return self.vertList.keys()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.vertList.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting & Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bubbleSort(alist):\n",
    "    for passnum in range(len(alist)-1,0,-1):\n",
    "        for i in range(passnum):\n",
    "            if alist[i]>alist[i+1]:\n",
    "                temp = alist[i]\n",
    "                alist[i] = alist[i+1]\n",
    "                alist[i+1] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def selectionSort(alist):\n",
    "   for fillslot in range(len(alist)-1,0,-1):\n",
    "       positionOfMax=0\n",
    "       for location in range(1,fillslot+1):\n",
    "           if alist[location]>alist[positionOfMax]:\n",
    "               positionOfMax = location\n",
    "\n",
    "       temp = alist[fillslot]\n",
    "       alist[fillslot] = alist[positionOfMax]\n",
    "       alist[positionOfMax] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quickSortHelper(alist,first,last):\n",
    "    if first<last:\n",
    "\n",
    "        splitpoint = partition(alist,first,last)\n",
    "\n",
    "        quickSortHelper(alist,first,splitpoint-1)\n",
    "        quickSortHelper(alist,splitpoint+1,last)\n",
    "\n",
    "\n",
    "def partition(alist,first,last):\n",
    "    pivotvalue = alist[first]\n",
    "\n",
    "    leftmark = first+1\n",
    "    rightmark = last\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "        while leftmark <= rightmark and alist[leftmark] <= pivotvalue: \n",
    "            leftmark = leftmark + 1\n",
    "def quickSort(alist):\n",
    "    quickSortHelper(alist,0,len(alist)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insertionSort(alist):\n",
    "   for index in range(1,len(alist)):\n",
    "\n",
    "     currentvalue = alist[index]\n",
    "     position = index\n",
    "\n",
    "     while position>0 and alist[position-1]>currentvalue:\n",
    "         alist[position]=alist[position-1]\n",
    "         position = position-1\n",
    "\n",
    "     alist[position]=currentvalue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "list = random.sample(range(10000), 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.05200004578\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "time0 = time()\n",
    "sortedlist = insertionSort(list)\n",
    "sorttime = time() - time0\n",
    "print(sorttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84700012207\n"
     ]
    }
   ],
   "source": [
    "time0 = time()\n",
    "sortedlist = selectionSort(list)\n",
    "sorttime = time() - time0\n",
    "print(sorttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.884000062943\n"
     ]
    }
   ],
   "source": [
    "time0 = time()\n",
    "sortedlist = bubbleSort(list)\n",
    "sorttime = time() - time0\n",
    "print(sorttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binarySearch(alist, item):\n",
    "    first = 0\n",
    "    last = len(alist)-1\n",
    "    found = False\n",
    "    while first<=last and not found: midpoint = (first + last)//2\n",
    "    if alist[midpoint] == item: found = True\n",
    "    else:\n",
    "        if item < alist[midpoint]:last = midpoint-1\n",
    "        else: first = midpoint+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression & Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-edfa34cb1692>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;31m# Test simple linear regression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m \u001b[0mrmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_algorithm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimple_linear_regression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RMSE: %.3f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrmse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-edfa34cb1692>\u001b[0m in \u001b[0;36mevaluate_algorithm\u001b[1;34m(dataset, algorithm)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Evaluate regression algorithm on training dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mevaluate_algorithm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mtest_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                 \u001b[0mrow_copy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "# Calculate root mean squared error\n",
    "def rmse_metric(actual, predicted):\n",
    "    sum_error = 0.0\n",
    "    for i in range(len(actual)):\n",
    "        prediction_error = predicted[i] - actual[i]\n",
    "        sum_error += (prediction_error ** 2)\n",
    "    mean_error = sum_error / float(len(actual))\n",
    "    return sqrt(mean_error)\n",
    "\n",
    "# Evaluate regression algorithm on training dataset\n",
    "def evaluate_algorithm(dataset, algorithm):\n",
    "    test_set = list()\n",
    "    for row in dataset:\n",
    "        row_copy = list(row)\n",
    "        row_copy[-1] = None\n",
    "        test_set.append(row_copy)\n",
    "    predicted = algorithm(dataset, test_set)\n",
    "    print(predicted)\n",
    "    actual = [row[-1] for row in dataset]\n",
    "    rmse = rmse_metric(actual, predicted)\n",
    "    return rmse\n",
    "\n",
    "# Calculate the mean value of a list of numbers\n",
    "def mean(values):\n",
    "    return sum(values) / float(len(values))\n",
    "\n",
    "# Calculate covariance between x and y\n",
    "def covariance(x, mean_x, y, mean_y):\n",
    "    covar = 0.0\n",
    "    for i in range(len(x)):\n",
    "        covar += (x[i] - mean_x) * (y[i] - mean_y)\n",
    "    return covar\n",
    "\n",
    "# Calculate the variance of a list of numbers\n",
    "def variance(values, mean):\n",
    "    return sum([(x-mean)**2 for x in values])\n",
    "\n",
    "# Calculate coefficients\n",
    "def coefficients(dataset):\n",
    "    x = [row[0] for row in dataset]\n",
    "    y = [row[1] for row in dataset]\n",
    "    x_mean, y_mean = mean(x), mean(y)\n",
    "    b1 = covariance(x, x_mean, y, y_mean) / variance(x, x_mean)\n",
    "    b0 = y_mean - b1 * x_mean\n",
    "    return [b0, b1]\n",
    "\n",
    "# Simple linear regression algorithm\n",
    "def simple_linear_regression(train, test):\n",
    "    predictions = list()\n",
    "    b0, b1 = coefficients(train)\n",
    "    for row in test:\n",
    "        yhat = b0 + b1 * row[0]\n",
    "        predictions.append(yhat)\n",
    "    return predictions\n",
    "\n",
    "# Test simple linear regression\n",
    "dataset = [[1, 1], [2, 3], [4, 3], [3, 2], [5, 5]]\n",
    "rmse = evaluate_algorithm(dataset, simple_linear_regression)\n",
    "print('RMSE: %.3f' % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-45-8b9710f2b4af>, line 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-45-8b9710f2b4af>\"\u001b[1;36m, line \u001b[1;32m32\u001b[0m\n\u001b[1;33m    print(f'loss: {self.__loss(h, y)} \\t')\u001b[0m\n\u001b[1;37m                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, lr=0.01, num_iter=100000, fit_intercept=True, verbose=False):\n",
    "        self.lr = lr\n",
    "        self.num_iter = num_iter\n",
    "        self.fit_intercept = fit_intercept\n",
    "    \n",
    "    def __add_intercept(self, X):\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        return np.concatenate((intercept, X), axis=1)\n",
    "    \n",
    "    def __sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    def __loss(self, h, y):\n",
    "        return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if self.fit_intercept:\n",
    "            X = self.__add_intercept(X)\n",
    "        \n",
    "        # weights initialization\n",
    "        self.theta = np.zeros(X.shape[1])\n",
    "        \n",
    "        for i in range(self.num_iter):\n",
    "            z = np.dot(X, self.theta)\n",
    "            h = self.__sigmoid(z)\n",
    "            gradient = np.dot(X.T, (h - y)) / y.size\n",
    "            self.theta -= self.lr * gradient\n",
    "            \n",
    "            if(self.verbose == True and i % 10000 == 0):\n",
    "                z = np.dot(X, self.theta)\n",
    "                h = self.__sigmoid(z)\n",
    "                print(f'loss: {self.__loss(h, y)} \\t')\n",
    "    \n",
    "    def predict_prob(self, X):\n",
    "        if self.fit_intercept:\n",
    "            X = self.__add_intercept(X)\n",
    "    \n",
    "        return self.__sigmoid(np.dot(X, self.theta))\n",
    "    \n",
    "    def predict(self, X, threshold):\n",
    "        return self.predict_prob(X) >= threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees, K-Means and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_split(index, value, dataset):\n",
    "    left, right = list(), list()\n",
    "    for row in dataset:\n",
    "        if row[index] < value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return left, right\n",
    " \n",
    "# Calculate the Gini index for a split dataset\n",
    "def gini_index(groups, classes):\n",
    "    # count all samples at split point\n",
    "    n_instances = float(sum([len(group) for group in groups]))\n",
    "    # sum weighted Gini index for each group\n",
    "    gini = 0.0\n",
    "    for group in groups:\n",
    "        size = float(len(group))\n",
    "        # avoid divide by zero\n",
    "        if size == 0:\n",
    "            continue\n",
    "        score = 0.0\n",
    "        # score the group based on the score for each class\n",
    "        for class_val in classes:\n",
    "            p = [row[-1] for row in group].count(class_val) / size\n",
    "            score += p * p\n",
    "        # weight the group score by its relative size\n",
    "        gini += (1.0 - score) * (size / n_instances)\n",
    "    return gini\n",
    " \n",
    "# Select the best split point for a dataset\n",
    "def get_split(dataset):\n",
    "    class_values = list(set(row[-1] for row in dataset))\n",
    "    b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "    for index in range(len(dataset[0])-1):\n",
    "        for row in dataset:\n",
    "            groups = test_split(index, row[index], dataset)\n",
    "            gini = gini_index(groups, class_values)\n",
    "            print('X%d < %.3f Gini=%.3f' % ((index+1), row[index], gini))\n",
    "            if gini < b_score:\n",
    "                b_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
    "    return {'index':b_index, 'value':b_value, 'groups':b_groups}\n",
    " \n",
    "dataset = [[2.771244718,1.784783929,0],\n",
    "    [1.728571309,1.169761413,0],\n",
    "    [3.678319846,2.81281357,0],\n",
    "    [3.961043357,2.61995032,0],\n",
    "    [2.999208922,2.209014212,0],\n",
    "    [7.497545867,3.162953546,1],\n",
    "    [9.00220326,3.339047188,1],\n",
    "    [7.444542326,0.476683375,1],\n",
    "    [10.12493903,3.234550982,1],\n",
    "    [6.642287351,3.319983761,1]]\n",
    "split = get_split(dataset)\n",
    "print('Split: [X%d < %.3f]' % ((split['index']+1), split['value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class K_Means:\n",
    "    def __init__(self, k=2, tol=0.001, max_iter=300):\n",
    "        self.k = k\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def fit(self,data):\n",
    "\n",
    "        self.centroids = {}\n",
    "\n",
    "        for i in range(self.k):\n",
    "            self.centroids[i] = data[i]\n",
    "\n",
    "        for i in range(self.max_iter):\n",
    "            self.classifications = {}\n",
    "\n",
    "            for i in range(self.k):\n",
    "                self.classifications[i] = []\n",
    "\n",
    "            for featureset in data:\n",
    "                distances = [np.linalg.norm(featureset-self.centroids[centroid]) for centroid in self.centroids]\n",
    "                classification = distances.index(min(distances))\n",
    "                self.classifications[classification].append(featureset)\n",
    "\n",
    "            prev_centroids = dict(self.centroids)\n",
    "\n",
    "            for classification in self.classifications:\n",
    "                self.centroids[classification] = np.average(self.classifications[classification],axis=0)\n",
    "\n",
    "            optimized = True\n",
    "\n",
    "            for c in self.centroids:\n",
    "                original_centroid = prev_centroids[c]\n",
    "                current_centroid = self.centroids[c]\n",
    "                if np.sum((current_centroid-original_centroid)/original_centroid*100.0) > self.tol:\n",
    "                    print(np.sum((current_centroid-original_centroid)/original_centroid*100.0))\n",
    "                    optimized = False\n",
    "\n",
    "            if optimized:\n",
    "                break\n",
    "\n",
    "    def predict(self,data):\n",
    "        distances = [np.linalg.norm(data-self.centroids[centroid]) for centroid in self.centroids]\n",
    "        classification = distances.index(min(distances))\n",
    "        return classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA\n",
    "1. get the mean vector\n",
    "2. get the covariance matrix\n",
    "3. get the eigenvectors and eigenvalues\n",
    "4. sort the eigenvectors by eigenvalues\n",
    "5. take top 'k' eigenvectors\n",
    "6. visualize top k eigenvectors\n",
    "7. Convert the data to the top k eigenvector subspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.array([ [0,0,1],[0,1,1],[1,0,1],[1,1,1] ])\n",
    "y = np.array([[0,1,1,0]]).T\n",
    "syn0 = 2*np.random.random((3,4)) - 1\n",
    "syn1 = 2*np.random.random((4,1)) - 1\n",
    "for j in xrange(60000): \n",
    "    l1 = 1/(1+np.exp(-(np.dot(X,syn0))))\n",
    "    l2 = 1/(1+np.exp(-(np.dot(l1,syn1))))\n",
    "    l2_delta = (y - l2)*(l2*(1-l2))\n",
    "    l1_delta = l2_delta.dot(syn1.T) * (l1 * (1-l1))\n",
    "    syn1 += l1.T.dot(l2_delta)\n",
    "    syn0 += X.T.dot(l1_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural_Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output After Training:\n",
      "[[ 0.00966807]\n",
      " [ 0.00786348]\n",
      " [ 0.99359097]\n",
      " [ 0.99211752]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# sigmoid function\n",
    "def nonlin(x,deriv=False):\n",
    "    if(deriv==True):\n",
    "        return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))\n",
    "    \n",
    "# input dataset\n",
    "X = np.array([  [0,0,1],\n",
    "                [0,1,1],\n",
    "                [1,0,1],\n",
    "                [1,1,1] ])\n",
    "    \n",
    "# output dataset            \n",
    "y = np.array([[0,0,1,1]]).T\n",
    "\n",
    "# seed random numbers to make calculation\n",
    "# deterministic (just a good practice)\n",
    "np.random.seed(88)\n",
    "\n",
    "# initialize weights randomly with mean 0\n",
    "syn0 = 2*np.random.random((3,1)) - 1\n",
    "\n",
    "for iter in xrange(10000):\n",
    "\n",
    "    # forward propagation\n",
    "    l0 = X\n",
    "    l1 = nonlin(np.dot(l0,syn0))\n",
    "\n",
    "    # how much did we miss?\n",
    "    l1_error = y - l1\n",
    "\n",
    "    # multiply how much we missed by the \n",
    "    # slope of the sigmoid at the values in l1\n",
    "    l1_delta = l1_error * nonlin(l1,True)\n",
    "\n",
    "    # update weights\n",
    "    syn0 += np.dot(l0.T,l1_delta)\n",
    "\n",
    "print \"Output After Training:\"\n",
    "print l1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1+ np.exp(-x))\n",
    "\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1.0 - x)\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, x, y):\n",
    "        self.input      = x\n",
    "        self.weights1   = np.random.rand(self.input.shape[1],4) \n",
    "        self.weights2   = np.random.rand(4,1)                 \n",
    "        self.y          = y\n",
    "        self.output     = np.zeros(self.y.shape)\n",
    "\n",
    "\n",
    "    def feedforward(self):\n",
    "        self.layer1 = sigmoid(np.dot(self.input, self.weights1))\n",
    "        self.output = sigmoid(np.dot(self.layer1, self.weights2))\n",
    "\n",
    "\n",
    "    def backprop(self):\n",
    "        # application of the chain rule to find derivative of the loss function with respect to weights2 and weights1\n",
    "        d_weights2 = np.dot(self.layer1.T, (2*(self.y - self.output) * sigmoid_derivative(self.output)))\n",
    "        d_weights1 = np.dot(self.input.T,  (np.dot(2*(self.y - self.output) * sigmoid_derivative(self.output), self.weights2.T) * sigmoid_derivative(self.layer1)))\n",
    "\n",
    "\n",
    "        # update the weights with the derivative (slope) of the loss function\n",
    "        self.weights1 += d_weights1\n",
    "        self.weights2 += d_weights2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    X = np.array([[0,0,1],\n",
    "                  [0,1,1],\n",
    "                  [1,0,1],\n",
    "                  [1,1,1]])\n",
    "    y = np.array([[0],[1],[1],[0]])\n",
    "    nn = NeuralNetwork(X,y)\n",
    "\n",
    "\n",
    "    for i in range(1500):\n",
    "        nn.feedforward()\n",
    "        nn.backprop()\n",
    "\n",
    "\n",
    "    print(nn.output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def sigmoid(x): \n",
    "    return 1. / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(values): \n",
    "    return values*(1-values)\n",
    "\n",
    "def tanh_derivative(values): \n",
    "    return 1. - values ** 2\n",
    "\n",
    "# createst uniform random array w/ values in [a,b) and shape args\n",
    "def rand_arr(a, b, *args): \n",
    "    np.random.seed(0)\n",
    "    return np.random.rand(*args) * (b - a) + a\n",
    "\n",
    "class LstmParam:\n",
    "    def __init__(self, mem_cell_ct, x_dim):\n",
    "        self.mem_cell_ct = mem_cell_ct\n",
    "        self.x_dim = x_dim\n",
    "        concat_len = x_dim + mem_cell_ct\n",
    "        # weight matrices\n",
    "        self.wg = rand_arr(-0.1, 0.1, mem_cell_ct, concat_len)\n",
    "        self.wi = rand_arr(-0.1, 0.1, mem_cell_ct, concat_len) \n",
    "        self.wf = rand_arr(-0.1, 0.1, mem_cell_ct, concat_len)\n",
    "        self.wo = rand_arr(-0.1, 0.1, mem_cell_ct, concat_len)\n",
    "        # bias terms\n",
    "        self.bg = rand_arr(-0.1, 0.1, mem_cell_ct) \n",
    "        self.bi = rand_arr(-0.1, 0.1, mem_cell_ct) \n",
    "        self.bf = rand_arr(-0.1, 0.1, mem_cell_ct) \n",
    "        self.bo = rand_arr(-0.1, 0.1, mem_cell_ct) \n",
    "        # diffs (derivative of loss function w.r.t. all parameters)\n",
    "        self.wg_diff = np.zeros((mem_cell_ct, concat_len)) \n",
    "        self.wi_diff = np.zeros((mem_cell_ct, concat_len)) \n",
    "        self.wf_diff = np.zeros((mem_cell_ct, concat_len)) \n",
    "        self.wo_diff = np.zeros((mem_cell_ct, concat_len)) \n",
    "        self.bg_diff = np.zeros(mem_cell_ct) \n",
    "        self.bi_diff = np.zeros(mem_cell_ct) \n",
    "        self.bf_diff = np.zeros(mem_cell_ct) \n",
    "        self.bo_diff = np.zeros(mem_cell_ct) \n",
    "\n",
    "    def apply_diff(self, lr = 1):\n",
    "        self.wg -= lr * self.wg_diff\n",
    "        self.wi -= lr * self.wi_diff\n",
    "        self.wf -= lr * self.wf_diff\n",
    "        self.wo -= lr * self.wo_diff\n",
    "        self.bg -= lr * self.bg_diff\n",
    "        self.bi -= lr * self.bi_diff\n",
    "        self.bf -= lr * self.bf_diff\n",
    "        self.bo -= lr * self.bo_diff\n",
    "        # reset diffs to zero\n",
    "        self.wg_diff = np.zeros_like(self.wg)\n",
    "        self.wi_diff = np.zeros_like(self.wi) \n",
    "        self.wf_diff = np.zeros_like(self.wf) \n",
    "        self.wo_diff = np.zeros_like(self.wo) \n",
    "        self.bg_diff = np.zeros_like(self.bg)\n",
    "        self.bi_diff = np.zeros_like(self.bi) \n",
    "        self.bf_diff = np.zeros_like(self.bf) \n",
    "        self.bo_diff = np.zeros_like(self.bo) \n",
    "\n",
    "class LstmState:\n",
    "    def __init__(self, mem_cell_ct, x_dim):\n",
    "        self.g = np.zeros(mem_cell_ct)\n",
    "        self.i = np.zeros(mem_cell_ct)\n",
    "        self.f = np.zeros(mem_cell_ct)\n",
    "        self.o = np.zeros(mem_cell_ct)\n",
    "        self.s = np.zeros(mem_cell_ct)\n",
    "        self.h = np.zeros(mem_cell_ct)\n",
    "        self.bottom_diff_h = np.zeros_like(self.h)\n",
    "        self.bottom_diff_s = np.zeros_like(self.s)\n",
    "    \n",
    "class LstmNode:\n",
    "    def __init__(self, lstm_param, lstm_state):\n",
    "        # store reference to parameters and to activations\n",
    "        self.state = lstm_state\n",
    "        self.param = lstm_param\n",
    "        # non-recurrent input concatenated with recurrent input\n",
    "        self.xc = None\n",
    "\n",
    "    def bottom_data_is(self, x, s_prev = None, h_prev = None):\n",
    "        # if this is the first lstm node in the network\n",
    "        if s_prev is None: s_prev = np.zeros_like(self.state.s)\n",
    "        if h_prev is None: h_prev = np.zeros_like(self.state.h)\n",
    "        # save data for use in backprop\n",
    "        self.s_prev = s_prev\n",
    "        self.h_prev = h_prev\n",
    "\n",
    "        # concatenate x(t) and h(t-1)\n",
    "        xc = np.hstack((x,  h_prev))\n",
    "        self.state.g = np.tanh(np.dot(self.param.wg, xc) + self.param.bg)\n",
    "        self.state.i = sigmoid(np.dot(self.param.wi, xc) + self.param.bi)\n",
    "        self.state.f = sigmoid(np.dot(self.param.wf, xc) + self.param.bf)\n",
    "        self.state.o = sigmoid(np.dot(self.param.wo, xc) + self.param.bo)\n",
    "        self.state.s = self.state.g * self.state.i + s_prev * self.state.f\n",
    "        self.state.h = self.state.s * self.state.o\n",
    "\n",
    "        self.xc = xc\n",
    "    \n",
    "    def top_diff_is(self, top_diff_h, top_diff_s):\n",
    "        # notice that top_diff_s is carried along the constant error carousel\n",
    "        ds = self.state.o * top_diff_h + top_diff_s\n",
    "        do = self.state.s * top_diff_h\n",
    "        di = self.state.g * ds\n",
    "        dg = self.state.i * ds\n",
    "        df = self.s_prev * ds\n",
    "\n",
    "        # diffs w.r.t. vector inside sigma / tanh function\n",
    "        di_input = sigmoid_derivative(self.state.i) * di \n",
    "        df_input = sigmoid_derivative(self.state.f) * df \n",
    "        do_input = sigmoid_derivative(self.state.o) * do \n",
    "        dg_input = tanh_derivative(self.state.g) * dg\n",
    "\n",
    "        # diffs w.r.t. inputs\n",
    "        self.param.wi_diff += np.outer(di_input, self.xc)\n",
    "        self.param.wf_diff += np.outer(df_input, self.xc)\n",
    "        self.param.wo_diff += np.outer(do_input, self.xc)\n",
    "        self.param.wg_diff += np.outer(dg_input, self.xc)\n",
    "        self.param.bi_diff += di_input\n",
    "        self.param.bf_diff += df_input       \n",
    "        self.param.bo_diff += do_input\n",
    "        self.param.bg_diff += dg_input       \n",
    "\n",
    "        # compute bottom diff\n",
    "        dxc = np.zeros_like(self.xc)\n",
    "        dxc += np.dot(self.param.wi.T, di_input)\n",
    "        dxc += np.dot(self.param.wf.T, df_input)\n",
    "        dxc += np.dot(self.param.wo.T, do_input)\n",
    "        dxc += np.dot(self.param.wg.T, dg_input)\n",
    "\n",
    "        # save bottom diffs\n",
    "        self.state.bottom_diff_s = ds * self.state.f\n",
    "        self.state.bottom_diff_h = dxc[self.param.x_dim:]\n",
    "\n",
    "class LstmNetwork():\n",
    "    def __init__(self, lstm_param):\n",
    "        self.lstm_param = lstm_param\n",
    "        self.lstm_node_list = []\n",
    "        # input sequence\n",
    "        self.x_list = []\n",
    "\n",
    "    def y_list_is(self, y_list, loss_layer):\n",
    "        \"\"\"\n",
    "        Updates diffs by setting target sequence \n",
    "        with corresponding loss layer. \n",
    "        Will *NOT* update parameters.  To update parameters,\n",
    "        call self.lstm_param.apply_diff()\n",
    "        \"\"\"\n",
    "        assert len(y_list) == len(self.x_list)\n",
    "        idx = len(self.x_list) - 1\n",
    "        # first node only gets diffs from label ...\n",
    "        loss = loss_layer.loss(self.lstm_node_list[idx].state.h, y_list[idx])\n",
    "        diff_h = loss_layer.bottom_diff(self.lstm_node_list[idx].state.h, y_list[idx])\n",
    "        # here s is not affecting loss due to h(t+1), hence we set equal to zero\n",
    "        diff_s = np.zeros(self.lstm_param.mem_cell_ct)\n",
    "        self.lstm_node_list[idx].top_diff_is(diff_h, diff_s)\n",
    "        idx -= 1\n",
    "\n",
    "        ### ... following nodes also get diffs from next nodes, hence we add diffs to diff_h\n",
    "        ### we also propagate error along constant error carousel using diff_s\n",
    "        while idx >= 0:\n",
    "            loss += loss_layer.loss(self.lstm_node_list[idx].state.h, y_list[idx])\n",
    "            diff_h = loss_layer.bottom_diff(self.lstm_node_list[idx].state.h, y_list[idx])\n",
    "            diff_h += self.lstm_node_list[idx + 1].state.bottom_diff_h\n",
    "            diff_s = self.lstm_node_list[idx + 1].state.bottom_diff_s\n",
    "            self.lstm_node_list[idx].top_diff_is(diff_h, diff_s)\n",
    "            idx -= 1 \n",
    "\n",
    "        return loss\n",
    "\n",
    "    def x_list_clear(self):\n",
    "        self.x_list = []\n",
    "\n",
    "    def x_list_add(self, x):\n",
    "        self.x_list.append(x)\n",
    "        if len(self.x_list) > len(self.lstm_node_list):\n",
    "            # need to add new lstm node, create new state mem\n",
    "            lstm_state = LstmState(self.lstm_param.mem_cell_ct, self.lstm_param.x_dim)\n",
    "            self.lstm_node_list.append(LstmNode(self.lstm_param, lstm_state))\n",
    "\n",
    "        # get index of most recent x input\n",
    "        idx = len(self.x_list) - 1\n",
    "        if idx == 0:\n",
    "            # no recurrent inputs yet\n",
    "            self.lstm_node_list[idx].bottom_data_is(x)\n",
    "        else:\n",
    "            s_prev = self.lstm_node_list[idx - 1].state.s\n",
    "            h_prev = self.lstm_node_list[idx - 1].state.h\n",
    "            self.lstm_node_list[idx].bottom_data_is(x, s_prev, h_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-b191eda18dc9>, line 34)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-b191eda18dc9>\"\u001b[1;36m, line \u001b[1;32m34\u001b[0m\n\u001b[1;33m    print(\"iter\", \"%2s\" % str(cur_iter), end=\": \")\u001b[0m\n\u001b[1;37m                                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from lstm import LstmParam, LstmNetwork\n",
    "\n",
    "\n",
    "class ToyLossLayer:\n",
    "    \"\"\"\n",
    "    Computes square loss with first element of hidden layer array.\n",
    "    \"\"\"\n",
    "    @classmethod\n",
    "    def loss(self, pred, label):\n",
    "        return (pred[0] - label) ** 2\n",
    "\n",
    "    @classmethod\n",
    "    def bottom_diff(self, pred, label):\n",
    "        diff = np.zeros_like(pred)\n",
    "        diff[0] = 2 * (pred[0] - label)\n",
    "        return diff\n",
    "\n",
    "\n",
    "def example_0():\n",
    "    # learns to repeat simple sequence from random inputs\n",
    "    np.random.seed(0)\n",
    "\n",
    "    # parameters for input data dimension and lstm cell count\n",
    "    mem_cell_ct = 100\n",
    "    x_dim = 50\n",
    "    lstm_param = LstmParam(mem_cell_ct, x_dim)\n",
    "    lstm_net = LstmNetwork(lstm_param)\n",
    "    y_list = [-0.5, 0.2, 0.1, -0.5]\n",
    "    input_val_arr = [np.random.random(x_dim) for _ in y_list]\n",
    "\n",
    "    for cur_iter in range(100):\n",
    "        print(\"iter\", \"%2s\" % str(cur_iter), end=\": \")\n",
    "        for ind in range(len(y_list)):\n",
    "            lstm_net.x_list_add(input_val_arr[ind])\n",
    "\n",
    "        print(\"y_pred = [\" +\n",
    "              \", \".join([\"% 2.5f\" % lstm_net.lstm_node_list[ind].state.h[0] for ind in range(len(y_list))]) +\n",
    "              \"]\", end=\", \")\n",
    "\n",
    "        loss = lstm_net.y_list_is(y_list, ToyLossLayer)\n",
    "        print(\"loss:\", \"%.3e\" % loss)\n",
    "        lstm_param.apply_diff(lr=0.1)\n",
    "        lstm_net.x_list_clear()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    example_0()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Models and Hidden Markov Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Su\n",
      "Su\n",
      "Walk\n",
      "\n",
      "\n",
      "R\n",
      "Shop\n",
      "\n",
      "\n",
      "Su\n",
      "Walk\n",
      "\n",
      "\n",
      "Su\n",
      "Clean\n",
      "\n",
      "\n",
      "Su\n",
      "Walk\n",
      "\n",
      "\n",
      "Su\n",
      "Shop\n",
      "\n",
      "\n",
      "R\n",
      "Clean\n",
      "\n",
      "\n",
      "Su\n",
      "Walk\n",
      "\n",
      "\n",
      "Su\n",
      "Walk\n",
      "\n",
      "\n",
      "Su\n",
      "Walk\n",
      "\n",
      "\n",
      "Su\n",
      "Clean\n",
      "\n",
      "\n",
      "R\n",
      "Shop\n",
      "\n",
      "\n",
      "Su\n",
      "Clean\n",
      "\n",
      "\n",
      "R\n",
      "Clean\n",
      "\n",
      "\n",
      "R\n",
      "Shop\n",
      "\n",
      "\n",
      "Su\n",
      "Walk\n",
      "\n",
      "\n",
      "Su\n",
      "Walk\n",
      "\n",
      "\n",
      "R\n",
      "Shop\n",
      "\n",
      "\n",
      "R\n",
      "Shop\n",
      "\n",
      "\n",
      "R\n",
      "Clean\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "start = ['R','Su']\n",
    "#Start probability\n",
    "p_start = [0.2,0.8]\n",
    "\n",
    "#t1 = [['R|R','Su|R'],['R|Su','Su|Su']]\n",
    "#Transition probability\n",
    "t1 = ['R','Su']\n",
    "p_t1=[[0.4,0.6],[0.3,0.7]]\n",
    "\n",
    "#t2 = [['W|R','Sh|R','C|R'],['W|Su','Sh|Su','C|Su']]\n",
    "t2 = ['Walk','Shop','Clean']\n",
    "#Emission probability\n",
    "p_t2=[[0.1,0.4,0.5],[0.6,0.3,0.1]]\n",
    "\n",
    "initial = np.random.choice(start,replace=True,p=p_start)\n",
    "\n",
    "#Number of days of simulation\n",
    "n = 20\n",
    "\n",
    "st = 1\n",
    "for i in range(n):\n",
    "    if st:\n",
    "        state = initial\n",
    "        st = 0\n",
    "        print(state)\n",
    "    if state == 'R':\n",
    "        activity = np.random.choice(t2,p=p_t2[0])\n",
    "        print(state)\n",
    "        print(activity)\n",
    "        state = np.random.choice(t1,p=p_t1[0])\n",
    "    elif state == 'Su':\n",
    "        activity = np.random.choice(t2,p=p_t2[1])\n",
    "        print(state)\n",
    "        print(activity)        \n",
    "        state = np.random.choice(t1,p=p_t1[1])\n",
    "    print(\"\\n\")\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    # Output (I printed out the hidden state too)\n",
    "    # R R Shop -- R Clean -- Su Walk -- Su Walk -- Su Walk -- Su Clean -- Su Walk -- R Shop -- R Shop -- R Shop -- R Shop -- Su Shop -- R Clean -- Su Walk -- Su Walk -- R Shop -- R Clean -- R Clean -- Su Shop -- Su Shop\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 7\n",
      "Iteration: 8\n",
      "Iteration: 9\n",
      "Iteration: 10\n",
      "Model transmission probabilities:\n",
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  1.44069481e-13   9.33776929e-01   7.18678407e-02   0.00000000e+00]\n",
      " [  1.00000000e+00   6.62230707e-02   8.64943107e-01   0.00000000e+00]\n",
      " [  0.00000000e+00   3.10801009e-14   6.31890522e-02   0.00000000e+00]]\n",
      "Model emission probabilities:\n",
      "[[ 0.64048542  0.        ]\n",
      " [ 0.14806851  0.5343899 ]\n",
      " [ 0.21144608  0.4656101 ]]\n",
      "Finding likelihood for ['1', '2', '3']\n",
      "Likelihood: 3.29569143885e-15\n"
     ]
    }
   ],
   "source": [
    "# A class for performing hidden markov models\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "class HMM():\n",
    "\n",
    "    def __init__(self, transmission_prob, emission_prob, obs=None):\n",
    "        '''\n",
    "        Note that this implementation assumes that n, m, and T are small\n",
    "        enough not to require underflow mitigation.\n",
    "\n",
    "        Required Inputs:\n",
    "        - transmission_prob: an (n+2) x (n+2) numpy array, initial, where n is\n",
    "        the number of hidden states\n",
    "        - emission_prob: an (m x n) 2-D numpy array, where m is the number of\n",
    "        possible observations\n",
    "\n",
    "        Optional Input:\n",
    "        - obs: a list of observation labels, in the same order as their\n",
    "        occurence within the emission probability matrix; otherwise, will assume\n",
    "        that the emission probabilities are in alpha-numerical order.\n",
    "        '''\n",
    "        self.transmission_prob = transmission_prob\n",
    "        self.emission_prob = emission_prob\n",
    "        self.n = self.emission_prob.shape[1]\n",
    "        self.m = self.emission_prob.shape[0]\n",
    "        self.observations = None\n",
    "        self.forward = []\n",
    "        self.backward = []\n",
    "        self.psi = []\n",
    "        self.obs = obs\n",
    "        self.emiss_ref = {}\n",
    "        self.forward_final = [0 , 0]\n",
    "        self.backward_final = [0 , 0]\n",
    "        self.state_probs = []\n",
    "        if obs is None and self.observations is not None:\n",
    "            self.obs = self.assume_obs()\n",
    "\n",
    "    def assume_obs(self):\n",
    "        '''\n",
    "        If observation labels are not given, will assume that the emission\n",
    "        probabilities are in alpha-numerical order.\n",
    "        '''\n",
    "        obs = list(set(list(self.observations)))\n",
    "        obs.sort()\n",
    "        for i in range(len(obs)):\n",
    "            self.emiss_ref[obs[i]] = i\n",
    "        return obs\n",
    "\n",
    "    def train(self, observations, iterations = 10, verbose=True):\n",
    "        '''\n",
    "        Trains the model parameters according to the observation sequence.\n",
    "\n",
    "        Input:\n",
    "        - observations: 1-D string array of T observations\n",
    "        '''\n",
    "        self.observations = observations\n",
    "        self.obs = self.assume_obs()\n",
    "        self.psi = [[[0.0] * (len(self.observations)-1) for i in range(self.n)] for i in range(self.n)]\n",
    "        self.gamma = [[0.0] * (len(self.observations)) for i in range(self.n)]\n",
    "        for i in range(iterations):\n",
    "            old_transmission = self.transmission_prob.copy()\n",
    "            old_emission = self.emission_prob.copy()\n",
    "            if verbose:\n",
    "                print(\"Iteration: {}\".format(i + 1))\n",
    "            self.expectation()\n",
    "            self.maximization()\n",
    "\n",
    "    def expectation(self):\n",
    "        '''\n",
    "        Executes expectation step.\n",
    "        '''\n",
    "        self.forward = self.forward_recurse(len(self.observations))\n",
    "        self.backward = self.backward_recurse(0)\n",
    "        self.get_gamma()\n",
    "        self.get_psi()\n",
    "\n",
    "    def get_gamma(self):\n",
    "        '''\n",
    "        Calculates the gamma matrix.\n",
    "        '''\n",
    "        self.gamma = [[0, 0] for i in range(len(self.observations))]\n",
    "        for i in range(len(self.observations)):\n",
    "            self.gamma[i][0] = (float(self.forward[0][i] * self.backward[0][i]) /\n",
    "                                float(self.forward[0][i] * self.backward[0][i] +\n",
    "                                self.forward[1][i] * self.backward[1][i]))\n",
    "            self.gamma[i][1] = (float(self.forward[1][i] * self.backward[1][i]) /\n",
    "                                float(self.forward[0][i] * self.backward[0][i] +\n",
    "                                self.forward[1][i] * self.backward[1][i]))\n",
    "\n",
    "    def get_psi(self):\n",
    "        '''\n",
    "        Runs the psi calculation.\n",
    "        '''\n",
    "        for t in range(1, len(self.observations)):\n",
    "            for j in range(self.n):\n",
    "                for i in range(self.n):\n",
    "                    self.psi[i][j][t-1] = self.calculate_psi(t, i, j)\n",
    "\n",
    "    def calculate_psi(self, t, i, j):\n",
    "        '''\n",
    "        Calculates the psi for a transition from i->j for t > 0.\n",
    "        '''\n",
    "        alpha_tminus1_i = self.forward[i][t-1]\n",
    "        a_i_j = self.transmission_prob[j+1][i+1]\n",
    "        beta_t_j = self.backward[j][t]\n",
    "        observation = self.observations[t]\n",
    "        b_j = self.emission_prob[self.emiss_ref[observation]][j]\n",
    "        denom = float(self.forward[0][i] * self.backward[0][i] + self.forward[1][i] * self.backward[1][i])\n",
    "        return (alpha_tminus1_i * a_i_j * beta_t_j * b_j) / denom\n",
    "\n",
    "    def maximization(self):\n",
    "        '''\n",
    "        Executes maximization step.\n",
    "        '''\n",
    "        self.get_state_probs()\n",
    "        for i in range(self.n):\n",
    "            self.transmission_prob[i+1][0] = self.gamma[0][i]\n",
    "            self.transmission_prob[-1][i+1] = self.gamma[-1][i] / self.state_probs[i]\n",
    "            for j in range(self.n):\n",
    "                self.transmission_prob[j+1][i+1] = self.estimate_transmission(i, j)\n",
    "            for obs in range(self.m):\n",
    "                self.emission_prob[obs][i] = self.estimate_emission(i, obs)\n",
    "\n",
    "    def get_state_probs(self):\n",
    "        '''\n",
    "        Calculates total probability of a given state.\n",
    "        '''\n",
    "        self.state_probs = [0] * self.n\n",
    "        for state in range(self.n):\n",
    "            summ = 0\n",
    "            for row in self.gamma:\n",
    "                summ += row[state]\n",
    "            self.state_probs[state] = summ\n",
    "\n",
    "    def estimate_transmission(self, i, j):\n",
    "        '''\n",
    "        Estimates transmission probabilities from i to j.\n",
    "        '''\n",
    "        return sum(self.psi[i][j]) / self.state_probs[i]\n",
    "\n",
    "    def estimate_emission(self, j, observation):\n",
    "        '''\n",
    "        Estimate emission probability for an observation from state j.\n",
    "        '''\n",
    "        observation = self.obs[observation]\n",
    "        ts = [i for i in range(len(self.observations)) if self.observations[i] == observation]\n",
    "        for i in range(len(ts)):\n",
    "            ts[i] = self.gamma[ts[i]][j]\n",
    "        return sum(ts) / self.state_probs[j]\n",
    "\n",
    "    def backward_recurse(self, index):\n",
    "        '''\n",
    "        Runs the backward recursion.\n",
    "        '''\n",
    "        # Initialization at T\n",
    "        if index == (len(self.observations) - 1):\n",
    "            backward = [[0.0] * (len(self.observations)) for i in range(self.n)]\n",
    "            for state in range(self.n):\n",
    "                backward[state][index] = self.backward_initial(state)\n",
    "            return backward\n",
    "        # Recursion for T --> 0\n",
    "        else:\n",
    "            backward = self.backward_recurse(index+1)\n",
    "            for state in range(self.n):\n",
    "                if index >= 0:\n",
    "                    backward[state][index] = self.backward_probability(index, backward, state)\n",
    "                if index == 0:\n",
    "                    self.backward_final[state] = self.backward_probability(index, backward, 0, final=True)\n",
    "            return backward\n",
    "\n",
    "    def backward_initial(self, state):\n",
    "        '''\n",
    "        Initialization of backward probabilities.\n",
    "        '''\n",
    "        return self.transmission_prob[self.n + 1][state + 1]\n",
    "\n",
    "    def backward_probability(self, index, backward, state, final=False):\n",
    "        '''\n",
    "        Calculates the backward probability at index = t.\n",
    "        '''\n",
    "        p = [0] * self.n\n",
    "        for j in range(self.n):\n",
    "            observation = self.observations[index + 1]\n",
    "            if not final:\n",
    "                a = self.transmission_prob[j + 1][state + 1]\n",
    "            else:\n",
    "                a = self.transmission_prob[j + 1][0]\n",
    "            b = self.emission_prob[self.emiss_ref[observation]][j]\n",
    "            beta = backward[j][index + 1]\n",
    "            p[j] = a * b * beta\n",
    "        return sum(p)\n",
    "\n",
    "    def forward_recurse(self, index):\n",
    "        '''\n",
    "        Executes forward recursion.\n",
    "        '''\n",
    "        # Initialization\n",
    "        if index == 0:\n",
    "            forward = [[0.0] * (len(self.observations)) for i in range(self.n)]\n",
    "            for state in range(self.n):\n",
    "                forward[state][index] = self.forward_initial(self.observations[index], state)\n",
    "            return forward\n",
    "        # Recursion\n",
    "        else:\n",
    "            forward = self.forward_recurse(index-1)\n",
    "            for state in range(self.n):\n",
    "                if index != len(self.observations):\n",
    "                    forward[state][index] = self.forward_probability(index, forward, state)\n",
    "                else:\n",
    "                    # Termination\n",
    "                    self.forward_final[state] = self.forward_probability(index, forward, state, final=True)\n",
    "            return forward\n",
    "\n",
    "    def forward_initial(self, observation, state):\n",
    "        '''\n",
    "        Calculates initial forward probabilities.\n",
    "        '''\n",
    "        self.transmission_prob[state + 1][0]\n",
    "        self.emission_prob[self.emiss_ref[observation]][state]\n",
    "        return self.transmission_prob[state + 1][0] * self.emission_prob[self.emiss_ref[observation]][state]\n",
    "\n",
    "    def forward_probability(self, index, forward, state, final=False):\n",
    "        '''\n",
    "        Calculates the alpha for index = t.\n",
    "        '''\n",
    "        p = [0] * self.n\n",
    "        for prev_state in range(self.n):\n",
    "            if not final:\n",
    "                # Recursion\n",
    "                obs_index = self.emiss_ref[self.observations[index]]\n",
    "                p[prev_state] = forward[prev_state][index-1] * self.transmission_prob[state + 1][prev_state + 1] * self.emission_prob[obs_index][state]\n",
    "            else:\n",
    "                # Termination\n",
    "                p[prev_state] = forward[prev_state][index-1] * self.transmission_prob[self.n][prev_state + 1]\n",
    "        return sum(p)\n",
    "\n",
    "    def likelihood(self, new_observations):\n",
    "        '''\n",
    "        Returns the probability of a observation sequence based on current model\n",
    "        parameters.\n",
    "        '''\n",
    "        new_hmm = HMM(self.transmission_prob, self.emission_prob)\n",
    "        new_hmm.observations = new_observations\n",
    "        new_hmm.obs = new_hmm.assume_obs()\n",
    "        forward = new_hmm.forward_recurse(len(new_observations))\n",
    "        return sum(new_hmm.forward_final)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Example inputs from Jason Eisner's Ice Cream and Baltimore Summer example\n",
    "    # http://www.cs.jhu.edu/~jason/papers/#eisner-2002-tnlp\n",
    "    emission = np.array([[0.7, 0], [0.2, 0.3], [0.1, 0.7]])\n",
    "    transmission = np.array([ [0, 0, 0, 0], [0.5, 0.8, 0.2, 0], [0.5, 0.1, 0.7, 0], [0, 0.1, 0.1, 0]])\n",
    "    observations = ['2','3','3','2','3','2','3','2','2','3','1','3','3','1','1',\n",
    "                    '1','2','1','1','1','3','1','2','1','1','1','2','3','3','2',\n",
    "                    '3','2','2']\n",
    "    model = HMM(transmission, emission)\n",
    "    model.train(observations)\n",
    "    print(\"Model transmission probabilities:\\n{}\".format(model.transmission_prob))\n",
    "    print(\"Model emission probabilities:\\n{}\".format(model.emission_prob))\n",
    "    # Probability of a new sequence\n",
    "    new_seq = ['1', '2', '3']\n",
    "    print(\"Finding likelihood for {}\".format(new_seq))\n",
    "    likelihood = model.likelihood(new_seq)\n",
    "    print(\"Likelihood: {}\".format(likelihood))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://plot.ly/ipython-notebooks/principal-component-analysis/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://sebastianraschka.com/Articles/2014_pca_step_by_step.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
